\label{Chapter4}

\newlength\figureheight
\newlength\figurewidth

\chapter{Experimental Validation}

\section{Scope of Experiments}

The purpose of the experiments is to validate the proposed system as
well as its robustness in various terrains and configurations.
Since the autonomous navigation of the robot is out of the scope of this
thesis, the mapping procedure is only indirectly validated as part of the
SLAM system.
Thus, the main focus of the experiments is the relative and absolute
localization techniques that were developed.

\subsection{Data Collection}

The performed experiments were executed by means of
\textit{Software In the Loop} (SIL) tests using precollected data.
The data were collected by the Planetary Robotics Lab team of the European
Space Agency as part of a two week test campaign that took
place in the Minas de San Jose desert in Tenerife, Spain with the aim to
validate the integration of the HDPR rover (Section \ref{hdpr_rover}) and
provide data for future research projects.
The aerial view of the local is presented in Figure \ref{fig:terrain}.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.3]{terrain}
    \caption[Aerial view of test field]{
        Aerial view of test field that was reconstructed using drone
        imagery.
    }
    \label{fig:terrain}
\end{figure}

For that reason, the collected dataset contains samples from:
\begin{enumerate*}[label=(\roman*)]
        \item three stereo camera sensors
        \item IMU sensor
        \item point clouds reconstructed from drone imagery
        \item GPS sensor.
\end{enumerate*}
These samples are used both as input to our system and as ground truth
information.

The environment in which the test data were collected, was chosen with
the aim to bear close resemblance to rough planetary terrains,
specifically to the one of Mars.
In particular, various geological properties such as the distribution
and the shape of the rocks is similar to the Martian terrain.

Finally, the speed of the robot in these datasets was chosen to be close
to the $\SI{10}{\cm \per sec}$ value, considering the long-range traverses it was
required to cover.
As such, for the first two experiments, the size of the local map is fixed at
$\SI{20 x 20}{\m}$ and its resolution at $\SI{10}{\cm \per cell}$,
while for the global map we presumed the resolution to be fixed at
$\SI{50}{\cm \per cell}$.
In the third experiment, the performance of our approach is validated against
these parameters, hence they are variable.

\subsection{Metrics} \label{metrics}

To quantify the experimental results and evaluate the outputs of the system,
it is necessary to introduce certain metrics:
\begin{itemize}
    \item \textbf{Mean square error (MSE) of pose graph}:
        This is a straightforward metric for benchmarking SLAM algorithms
        and can be defined as
        \begin{equation}
            \varepsilon_{MSE} (\hat{x}_{1:T}) = \frac{1}{T}
            \sum\limits_{t=1}^T (\hat{x}_t \ominus x_t)^2
        \end{equation}
        where
        $\hat{x}_{1:T}$ is the estimated pose graph,
        $x_{1:T}$ is the ground truth pose graph,
        $T$ is the number of samples and
        $x_i \ominus x_j$ is the distance between two poses.

        % TODO(ref): "On Measuring the Accuracy of SLAM Algorithms" paper

    \item \textbf{Root mean square deviation (RMSD) of pose graph}:
        Similarly to the MSE metric, this metric expresses the sample
        standard deviation of the differences between the estimated and the
        ground truth poses and can be defined as
        \begin{equation}
            \varepsilon_{RMSD} (\hat{x}_{1:T}) = \sqrt{\frac{1}{T}
            \sum\limits_{t=1}^T (y_t - \varepsilon_{MSE})^2}
        \end{equation}
        where $y_t$ is defined as $\hat{x}_t \ominus x_t$.
\end{itemize}

\section{Experiments on Pose Estimation}

\subsection{Relative Localization Results}

The purpose of this experiment is to test the accuracy of the Pose Estimation
module (see Section \ref{pose_estimation}) and evaluate its capabilities
in a relative localization (short-range) scenario.
To accomplish that, we will carry out each experiment with different parameter
sets with the aim of examining the system's sensitivity as well as finding an
optimal parameter configuration.

The main parameters that we will tune during the experiments are all related
to the particle filter and include
\begin{enumerate*}[label=(\roman*)]
        \item the number of particles used
        \item the resampling frequency
        \item the standard deviation of the Gaussian noise
            added to each particle.
\end{enumerate*}
Finally, the expected error of the estimated pose should ideally be in the
same order of magnitude as the size of one cell of the local map, so as to
ensure that the robot can distinguish the environment's obstacles with
a high-level of certainty.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.25]{terrain_1}
    \caption[Terrain of first experiment]{
        3D view of the terrain evaluated in the first experiment.
    }
    \label{fig:terrain_1}
\end{figure}

Figure \ref{fig:terrain_1} presents a view of the evaluated terrain of the
first scenario.
The terrain is depicted in the form of one dense point cloud which was
reconstructed from drone imagery.
The bird's eye view in Figures \ref{fig:bird_1_color} and \ref{fig:bird_1_raw}
shows the traverse of the robot in this scenario and compares the ground truth
path, the one from raw visual odometry and the one from the pose estimation.
In contrast to the visual odometry estimate (blue path), the pose estimate
of our system (red path) follows closely the ground truth (black path).
The richness of the terrain in features, which is visible in Figure
\ref{fig:bird_1_real}, is an advantage for relative localization since
the weights of the particles in the particle filter are updated using
scan matching.

\begin{figure}[t]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[scale=0.125]{bird_1_real}
        \caption{Point cloud projection}
        \label{fig:bird_1_real}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[scale=0.125]{bird_1_color}
        \caption{Global elevation map\\with an elevation colormap}
        \label{fig:bird_1_color}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[scale=0.125]{bird_1_raw}
        \caption{Global elevation map\\with raw elevation values}
        \label{fig:bird_1_raw}
    \end{subfigure}
    \caption[Traverse of first experiment]{Orthographic views of the
        environment and the robot's traverses in it. The black, red and
        blue colors correspond to the ground truth, SLAM and visual odometry
        paths accordingly.}
    \label{fig:bird_1}
\end{figure}

In particular, the influence the number of particles used has on the outcome
is shown in the comparison plot in Figure \ref{fig:error_vs_particles}.
We observe that the pose error decreases as we increase the number of particles
used in the particle filter, since the continuous space of the problem
is modelled more effectively.
However, increasing this parameter, brings a proportional increase to
the computation needs for every iteration of the filter.
As it is visible in the plot, a justified choice would be to use 100
particles for a balance of error and processing power.
Furthermore, it is important to notice that the drift in pose ($\SI{20}{\cm}$
in the case of 100 particles), is proportional to the robot's speed
($\SI{10}{\cm \per sec}$ in this experiment).

Regarding the second parameter, the plot in Figure
\ref{fig:error_vs_resampling} represents the same error as the previous plots,
with the difference that the number of particles is fixed to the value of 100
and the resampling frequency is the variable parameter.
It is visible that resampling too often or too rare has an impact on the
pose error.
This is due to the fact that by resampling, the particle population is gathered
near the best belief and as a result other possible solutions are eliminated.

\begin{figure}[h!]
    \centering
    \begin{subfigure}{0.75\textwidth}
        \centering
        \setlength\figureheight{6cm}
        \setlength\figurewidth{10cm}
        \input{Plots/error_vs_particles.tex}
        \caption{}
        \label{fig:error_vs_particles}
    \end{subfigure}
    \begin{subfigure}{0.75\textwidth}
        \centering
        \setlength\figureheight{6cm}
        \setlength\figurewidth{10cm}
        \input{Plots/error_vs_resampling.tex}
        \caption{}
        \label{fig:error_vs_resampling}
    \end{subfigure}
    \caption[Particle filter parameter influence]{
        (a) The influence the number of particles has on the pose error.
        (b) The influence the resampling frequency parameter has on the error.
    }
    \label{fig:parameter_comparison}
\end{figure}

For the purpose of further quantifying the results of this scenario altogether,
we calculate the $MSE$ and $RMSD$ metrics (defined in Section \ref{metrics})
for the parameter sets that were used to generate the above plots.
The values of these metrics are presented in Table \ref{table:metrics}.
The conclusion we drew from the plots are further confirmed using the two
metrics, since it is visible that the combination of a low number of particles
and a very low or very high resampling frequency increases the mean square
error and deviation by more than a factor of 4.

\begin{table}[h!]
    \centering
    \begin{tabular}{| c | c || c | c |}
        \hline
        Particle Number & Resampling frequency & MSE & RMSD \\
        \hline
        \hline
        20 & 10 & 301.6 & 287.3 \\
        \hline
        100 & 10 & 61.1 & 55.7 \\
        \hline
        200 & 10 & 46.4 & 41.3 \\
        \hline
        \hline
        100 & 1 & 252.0 & 240.8 \\
        \hline
        100 & 10 & 61.1 & 55.7 \\
        \hline
        100 & 50 & 168.4 & 157.5 \\
        \hline
    \end{tabular}
    \caption[Metrics on parameter sets for relative localization]{
        Values of the $MSE$ and $RMSD$ metrics on different sets of parameters.
    }
    \label{table:metrics}
\end{table}

\section{Experiments on Global Map Matching}

\subsection{Absolute Localization Results}

Contrary to relative localization, which is the ability to track the robot's
pose, absolute localization is the ability to maintain the tracked pose
which diverges due to accumulated errors over time.
For this purpose, we will test the system in a long-range
scenario where localization drifts are manifested and assess the robustness
of the Pose Correction module (see Section \ref{pose_correction})
Similarly to the pose estimation experiments, the expected error of the
corrected pose should ideally be in the same order of magnitude as the size of
one cell of the global map, in consideration of the fact that the global map's
resolution is higher than the resolution of the local map.

In the first scenario we evaluate the pose correction functionality in a
terrain with average feature richness, i.e. a terrain that contains
an average amount of elevation features such as rocks.
Figure \ref{fig:terrain_2} presents the view of such terrain as a dense
point cloud and Figure \ref{fig:bird_2} shows the traverse inside it.
It is visible that the SLAM estimation (red path) has a notable drift from
the ground truth values (black path).
Near the end of the traverse, we can observe the correction of the robot's pose
due to a successful match of the local to global elevation map.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.25]{terrain_2}
    \caption[Terrain of second experiment]{
        3D view of the terrain evaluated in the second experiment.
    }
    \label{fig:terrain_2}
\end{figure}

\begin{figure}[h!]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[scale=0.2]{bird_2_real}
        \caption{Point cloud projection}
        \label{fig:bird_2_real}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[scale=0.2]{bird_2_color}
        \caption{Global elevation map\\with an elevation colormap}
        \label{fig:bird_2_color}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[scale=0.2]{bird_2_raw}
        \caption{Global elevation map\\with raw elevation values}
        \label{fig:bird_2_raw}
    \end{subfigure}
    \caption[Traverse of second experiment]{Orthographic views of the
        environment and the robot's traverses in it. The black and red colors
        correspond to the ground truth and SLAM paths accordingly. The pose
        correction is visible in the end of the traverse.}
    \label{fig:bird_2}
\end{figure}

In addition, we present the orthographic projections of the gradient of the
global elevation map (Figure \ref{fig:bird_2_global_gradient_map}) where
the elevation features are more visible.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.25]{bird_2_global_gradient_map}
    \caption[Global gradient map for pose correction]{
        The global gradient map that the local map is matched to for
        pose correction.
    }
    \label{fig:bird_2_global_gradient_map}
\end{figure}

The correction of the accumulated error is more visible in the plot of
Figure \ref{fig:pose_correction_error}.
The score of the yielded result from the global to local map matching,
as well as the rate of correction, are visible in Table
\ref{table:pose_correction}.
We can notice that the score of the match is $97.1\%$ (where $100\%$ is a
perfect match - as defined in Section \ref{map_matching}) and since
the matching threshold was set to $95\%$, the match is accepted and used
to correct the robot's pose by $98.6\%$.

\begin{figure}[h!]
    \centering
    \setlength\figureheight{8cm}
    \setlength\figurewidth{12cm}
    \input{Plots/pose_correction.tex}
    \caption[Pose correction error over time plot]{
        Pose correction results of second experiment.
    }
    \label{fig:pose_correction_error}
\end{figure}

\begin{table}[h!]
    \centering
    \begin{tabular}{| c | c |}
        \hline
        Execution time of one iteration & $\SI{630}{\milli \second}$ \\
        \hline
        Total execution time & $\SI{12.6}{\sec}$ \\
        \hline
        \hline
        Percentage of correction in position & $98.6\%$ \\
        \hline
        Percentage of correction in orientation & $82.9\%$ \\
        \hline
        \hline
        Score of the matched location & $97.1\%$ \\
        \hline
        Acceptance threshold of match & $95\%$ \\
        \hline
    \end{tabular}
    \caption[Results of pose correction for absolute localization]{
        Resulting time, correction and score of the match found.
    }
    \label{table:pose_correction}
\end{table}

As we already mentioned, the exact moment of correction is determined by
the two criteria that were defined in the implementation of the Pose Correction
module (see Section \ref{pose_correction_criteria}).
However, since both of them are straightforward, their experimental
validation is left out.

\subsection{Map Resolution Viability}

In this experiment, we validate and measure the performance of our map
matching technique for absolute localization by performing the same
scenarios with different combinations of resolutions for the local and
global maps.
This is done with the aim to draw conclusions regarding the viability
of our approach w.r.t. the available global map data as well as
the processing capabilities of a robot.

Figure \ref{fig:global_map_resolution} presents the local and global elevation
maps with distinct resolution values.
Upon matching these maps, we observe the score of each match for every
combination of resolutions (Table \ref{table:map_resolutions}).
We can notice that a low resolution global map has more impact in the map
matching score than a low resolution local map.
In fact, a global map with a resolution of $\SI{2.0}{\m \per pixel}$ yields
poor results for every resolution of the local map.
On the other hand, a global map with a resolution of $\SI{1.0}{\m \per pixel}$
has the possibility to yield a high score only when the resolution of
the local map is high enough.

\begin{figure}[h!]
    \centering
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[scale=0.175]{global_resolution_1}
        \caption{}
        \label{fig:global_resolution_1}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[scale=0.175]{global_resolution_2}
        \caption{}
        \label{fig:global_resolution_2}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[scale=0.175]{global_resolution_3}
        \caption{}
        \label{fig:global_resolution_3}
    \end{subfigure}
    \caption[Global map resolution comparison]{Comparison of global gradient
        map resolution.
        (a) Resolution of $\SI{0.5}{\m \per pixel}$.
        (b) Resolution of $\SI{1.0}{\m \per pixel}$.
        (c) Resolution of $\SI{2.0}{\m \per pixel}$.
        }
    \label{fig:global_map_resolution}
\end{figure}

\begin{table}[h!]
    \centering
    \begin{tabular}{| c | c || c |}
        \hline
        Local map & Global map & Matching \\
        resolution & resolution & score \\
        \hline
        \hline
        0.1 & 0.5 & $97\%$ \\
        \hline
        0.1 & 1.0 & $76\%$ \\
        \hline
        0.1 & 2.0 & $48\%$ \\
        \hline
        \hline
        0.2 & 0.5 & $91\%$ \\
        \hline
        0.2 & 1.0 & $67\%$ \\
        \hline
        0.2 & 2.0 & $32\%$ \\
        \hline
        \hline
        0.5 & 0.5 & $72\%$ \\
        \hline
        0.5 & 1.0 & $36\%$ \\
        \hline
        0.5 & 2.0 & $25\%$ \\
        \hline
    \end{tabular}
    \caption[Local and global map resolution viability]{
        Score of match for combinations of local and global map resolutions.
    }
    \label{table:map_resolutions}
\end{table}

Although the size and resolution of the local map are parameters that we
determine, they are highly limited by the on board processing power of the
robot, since the higher the resolution the more computations must be performed.
On the other hand, the resolution of the global map is a parameter that is
determined by the equipped camera sensors of the orbiters and the
reconstruction techniques applied to the imagery received from those.
As the technology of the space industry advances, we can expect to observe
in the next few years an increase in the aforementioned resolution parameters
and, consequently, an increase in efficiency of the map matching techniques.
As an example, the HiRISE on board camera of the
\textit{Mars Reconnaissance Orbiter} can currently achieve a resolution of
$\SI{30}{\cm \per pixel}$ with the possibility to acquire stereo image pairs
with a precision better than $\SI{25}{\cm \per pixel}$ over locations of
high priority, i.e. potential landing site of future missions to Mars.
% TODO(ref): HiRISE fact

